---
title: "Classification"
author: "Jean-Pierre Lopez"
date: "22/12/2020"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

Le but de ce projet est d'identifier si oui ou non le client d'une banque fait défaut sur la base de certaines informations. C'est un exercice qui relève de la classification supervisée car l'on essaye de prédire une variable qualitative prenant deux valeurs.

On va commencencer par un traitement des données suivie d'une analyse approfondie pour chaque variable via des graphiques et des tableaux. Ces analyses nous permettrons de déterminer dans un premier temps les variables ayant un bon potentiel pour expliquer la probabilité de défaut. Enfin, nous proposerons quelques classifieurs.

 
```{r, message=FALSE}
library(readxl)
library(tidyverse)
library(caret)
library(glmnet) 
library(e1071) 
library(Matrix)

Credit <- read_xlsx("Credit_Cleaned.xlsx")
```

On a de l'information sur 5380 clients de la banque. Le nombre de variables explicatives est de 19.
 
```{r, echo=TRUE}
n = dim(Credit)[1]
dim(Credit)
```

On remarque l'absence de valeur manquante et la très grande présence de variables qualitatives.
On observe également la présence de variables de type POSIXct (date). On essayera d'extraire le plus d'information de ces variables afin de prédire Y.



```{r, echo=TRUE}
infodf = data.frame(type = t(data.frame(sapply(Credit, class)))[,1])
infodf$unique = sapply(Credit, function(x) length(unique(x)))
infodf$na = sapply(Credit, function(x) sum(is.na(x)))
infodf
```

# Traitement des donnnées de type date (POSIXct)

## Date de naissance (BirthDate)

`BirthDate` est une des variables de type date. Il serait intéressant d'extraire l'âge des clients via l'année de naissance mais nous ne connaissons pas la date à laquelle ce jeu de donnée a été conçu à priori.

```{r}
Credit$BirthDate[1]
```
Cependant on sait que dans la variable `Prod_Closed_Date` sont stockées les dates de cloture du prêt et que si la date est manquante alors elle est remplacée par la date la plus récente. `Prod_Closed_Date_Na` est la variable dummy qui indique si oui ou non la date de cloture est manquante. La date la plus récente est celle du 2 juin 2013, on soustrait à cette date le vecteur `BirthDate` pour obtenir l'âge des clients.

```{r}
head(as.data.frame(Credit[Credit$Prod_Closed_Date_NA==TRUE, "Prod_Closed_Date"]))

```

```{r}
latest_date = max(Credit$Prod_Closed_Date)
diff = difftime(latest_date, Credit$BirthDate, unit = "days")
Credit$Age =  floor(as.numeric(diff)/365)
head(Credit$Age)

```

## Date d'arrivée du client (Customer_Open_Date)

On extrait uniquement l'année et le mois d'arrivée du client, on ne pense pas qu'il soit possible que le jour du client puisse avoir un effet sur la probabilité de défaut.

```{r}
Credit$CustomerOpenDateYear = as.numeric(substring(Credit$Customer_Open_Date, 0,4))
Credit$CustomerOpenDateMonth = as.factor(substring(Credit$Customer_Open_Date, 6,7))
  
```


## Date d'ouverture et de fermeture du prêt financier (Prod_Decision_Date, Prod_Closed_Date)

On extrait la durée en mois du prêt afin d'examiner l'effet de celle-ci sur la probabilité de défaut. On sait que les prêts de longues dates ont des taux d'intérêts différents comparé aux prêts de courte période. On extrait également les années et les mois de ces deux variables.

```{r}
Credit$Credit_Duration = floor(as.numeric(Credit$Prod_Closed_Date - Credit$Prod_Decision_Date)/30)
Credit$Prod_Closed_DateYear= as.factor(substring(Credit$Prod_Closed_Date, 0,4))
Credit$Prod_Closed_DateMonth= as.factor(substring(Credit$Prod_Closed_Date, 6,7))
Credit$Prod_Decision_DateYear= as.factor(substring(Credit$Prod_Decision_Date, 0,4))
Credit$Prod_Decision_DateMonth= as.factor(substring(Credit$Prod_Decision_Date, 6,7))
  
```


```{r}
head(Credit$Credit_Duration)
  
```



# Analyse des données

On introduit une fonction qu'on va réutiliser tout au long de notre analyse. Elle permet de récupérer la proportion de clients faisant défaut pour chaque catégorie d'une variable qualitative.

```{r, echo=TRUE, warning=FALSE}
TableProp = function(data, y, x){
  n <-  dim(data)[1]
  n_x <-  table(data[x])
  names_x <-  names(table(data[x]))
  df <-  data.frame(numeric(2))
    
  for(j in 1:length(n_x)){
    df[names_x[j]] <- table(data[data[x] == names_x[j], y])/n_x[j]
  }
  df = df[-1]
  rownames(df) <- names(table(data[y]))
    
return(df)
}

```



## Credit issue

On commence par observer que la proportion des clients ne faisant pas défault est très importante. On fait face à un jeu de donnée déséquilibré et il faudra donc prendre en compte cet aspect au moment de la validation croisée. En effet, seulement 7.3% des clients ont fait défaut.

```{r, echo=TRUE}
table(Credit$Y)/n
```


## Type de client (Customer_Type)

On remarque que la proportion de client ayant fait défault est la même quelque soit la catégorie dans laquelle appartient le client. On pourrait supposer qu'un nouveau client à la même probabilité de faire défault qu'un ancien. Cette variable ne parait pas très importante pour expliquer la probabililité de faire défaut.  
Le graphique nous montre également qu'il y a plus de nouveaux clients que d'anciens clients.

```{r, warning=FALSE}
TableProp(Credit, "Y", "Customer_Type")
```


```{r, echo=FALSE}
ggplot(data = Credit) +
geom_bar(mapping = aes(x = Customer_Type, fill = Y))
  
```


## L'âge

On observe que les plus jeunes font défaut à un rythme plus élevé que les vieux clients. L'âge pourrait être une variable importante, on va créer des catégories d'âge pour avoir de meilleurs intérprétations.

```{r, echo=FALSE}
  ggplot(data = Credit) +
  geom_jitter(mapping = aes(x = Age, y = Y, color = Y), alpha = 0.4)
  
```

On observe un pattern intéressant: plus le client est jeune plus il est enclin à faire défaut. Parmis les clients âgés de plus de 60 ans, il y a seulement 5% d'entre eux qui ont fait défaut contre plus de 10% pour les clients les plus jeunes qui sont dans la vingtaine.  
On voit que la catégorie d'âge la plus représentée est celle des clients trentenaires.

```{r}
Credit$AgeCat <-  cut(Credit$Age, breaks = c(20, 30, 40 ,50,60,100), labels = c("20-30","31-40", "41-50", "51-60", "60+"))
TableProp(Credit, "Y", "AgeCat")

```


```{r, echo=FALSE}
  ggplot(data = Credit) +
  geom_bar(mapping = aes(x = AgeCat, fill = Y))
  
```

## Date d'arrivée du client (Customer_Open_Date)

A partir des années 2003-2004 le nombre de nouveaux clients s'est mit à augmenter sensiblement et a poursuivi son ascension jusqu'à la dernière date disponible, soit 2012. 
On remarque qu' à partir de 2005 le nombre de clients faisant défaut a commencé à augmenter. Avant cette date, très peu de clients faisaient défaut. Cette variable est intéressante car elle montre potentiellement que le risque de défaut, toute chose égale par ailleurs, augmente au fur et à mesure du temps.


```{r, echo=FALSE}
  ggplot(data = Credit) +
  geom_jitter(mapping = aes(x = CustomerOpenDateYear, y = Y, color = Y), alpha = 0.4)
  
```


```{r}
Credit$CustomerOpenDateYear <-  cut(Credit$CustomerOpenDateYear, breaks =  c(0,2005,2010,2012), labels = c("<2005","2006-2010", ">2010"))
TableProp(Credit, "Y", "CustomerOpenDateYear")
  
```


## Catégorie de client (P_Client)

On voit que la catégorie du client parraît importante pour expliquer la probabilté de faire défaut: les clients de catégorie NP font plus défaut que les autres.  

```{r}
TableProp(Credit, "Y", "P_Client")
  
```
On observe que parmis les nouveaux clients il n' y a aucun client de catégorie P.

```{r, echo=FALSE}
  ggplot(data = Credit) +
  geom_bar(mapping = aes(x = P_Client, fill = Y))+
  facet_grid(~Customer_Type)
  
```

Ce sont les clients de catégorie NP arrivés après 2010 qui font le plus défaut.

```{r, echo=FALSE}
  ggplot(data = Credit) +
  geom_bar(mapping = aes(x = P_Client, fill = Y))+
  facet_grid(~CustomerOpenDateYear)+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
  
```


## Niveau d'éducation (Educational_Level)

On remarque que parmis les clients ayant arrété leur éducation au lycée, sans le baccalauréat, aucun n'a fait défaut. L'effectif de ce groupe est également très petit (15).

```{r}
table(Credit$Educational_Level)
  
```

Afin d'éviter le surapprentissage, on regroupe au sein d'un même groupe les clients ayant eu le baccalauréat et les clients qui ont arrété avant.


```{r}
Credit$Educational_Level[Credit$Educational_Level == "Diploma"] = "Diploma or Less"
Credit$Educational_Level[Credit$Educational_Level == "Secondary or Less"] = "Diploma or Less"
TableProp(Credit, "Y", "Educational_Level")
  
```

La grande majorité des clients est allée à l'université et a obtenu un diplôme de licence. Ce sont ces mêmes clients qui ont le plus fait défaut.

```{r, echo=FALSE}
ggplot(data = Credit) +
geom_bar(mapping = aes(x = Educational_Level, fill = Y))
  
```

La filliale fait face à de plus en plus de clients de catégorie NP ayant un diplôme de licence au cours du temps. Et ce sont eux même, qui après 2010 font le plus défaut.



```{r, echo=FALSE}
  ggplot(data = Credit) +
  geom_bar(mapping = aes(x = Educational_Level, fill = Y))+
  facet_wrap(P_Client~CustomerOpenDateYear)+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
  
```

## Situation de famille (Marital_Status)

Tous les clients qui sont séparés, divorcés ou veufs seront considérés comme célibataires.


```{r}
table(Credit$Marital_Status)
Credit$Marital_Status[Credit$Marital_Status == "Separated"] = "Single"
Credit$Marital_Status[Credit$Marital_Status == "Widowed"] = "Single"  
Credit$Marital_Status[Credit$Marital_Status == "Divorced"] = "Single" 
```

```{r}
TableProp(Credit, "Y", "Marital_Status")
  
```

```{r, echo=FALSE}
  ggplot(data = Credit) +
  geom_bar(mapping = aes(x = Marital_Status, fill = Y))
```

## Nombre de personnes à charge (Number_Of_Dependant)

```{r}
table(Credit$Number_Of_Dependant)
Credit$Number_Of_DependantCat = cut(Credit$Number_Of_Dependant, c(-1,0,2,4, 20), labels = c("none", '1-2', "3-4", "5+"))
  
```

La proportion de défaut augmente avec le nombre de personnes à charge. Ce qui semble cohérent puisqu'ils ont plus de frais, ce qui diminue leur capacité de remboursement.

```{r}
TableProp(Credit, "Y", "Number_Of_DependantCat")
  
```

## Nombre d'années vivant dans la propriété actuelle (Years_At_Residence)

Les clients vivant sous le même toit depuis plus de 40 ans ne font quasiment pas défaut.
Plus on vit longtemps sous un même toit plus la proportion de clients faisant défaut baisse.

```{r, echo=FALSE}
  ggplot(data = Credit) +
  geom_jitter(mapping = aes(x = Years_At_Residence, y = Y, color = Y), alpha = 0.4)
  
```

```{r}
Credit$Years_At_ResidenceCat = cut(Credit$Years_At_Residence, breaks =  c(-1,10,20,30,40,100), labels = c("<10", "11-20", "21-30", "31-40", "40+"))
TableProp(Credit, "Y", "Years_At_ResidenceCat")  
```


## Nombre d'année dans le job actuel (Years_At_Business)

Les clients qui ont beaucoup d'expérience dans leur travail actuel font défaut à un rythme beaucoup moins élevé que ceux qui ont moins d'expérience. On remarque que certains clients travaillent depuis presque 100 ans dans leur job actuel, ce qui semble peu réaliste.


```{r, echo=FALSE}
  ggplot(data = Credit) +
  geom_jitter(mapping = aes(x = Years_At_Business, y = Y, color = Y), alpha = 0.4)
  
```

On examine ce groupe d'observations suspicieux et l'on confirme qu'il s'agit bien de valeurs aberrantes. En effet, on voit que ces personnes ont travaillé plus d'années que leur âge, ce qui est impossible.


```{r, warning=FALSE}
as.data.frame(Credit[Credit$Years_At_Business>40, c("BirthDate", "Years_At_Business", "Age")])
  
```

On va filtrer les valeurs improbables puis les corriger. On suppose que les individus peuvent commencer à travailler uniquement à partir de 18 ans. Les clients qui travaillent depuis plus de leurs âge moins 18 verront leur valeur de `Years_At_Business` modifié par la médiane.

```{r}
Credit$Years_At_Business[Credit$Years_At_Business > Credit$Age - 18] = median(Credit$Years_At_Business)
  
```



## Revenu annuel net (Net_Annual_Income)

On suppose qu'il soit exprimé en millier d'euros ou millier de dollars.

```{r}
summary(Credit$Net_Annual_Income)
  
```


```{r}
Credit$Net_Annual_Income = Credit$Net_Annual_Income*1000
head(Credit$Net_Annual_Income)
  
```

On remplace par la médiane les valeurs de `Net_Annual_Income` inférieures à 1000.

```{r, warning=FALSE}
as.data.frame(Credit[Credit$Net_Annual_Income<5000, "Net_Annual_Income"])
Credit$Net_Annual_Income[Credit$Net_Annual_Income<1000] = median(Credit$Net_Annual_Income)
  
```

On observe qu'aucun clients gagnant au-dessus de 1 million d'euros font défaut. On peut en conclure qu'au-delà de cette somme, le revenu paraît peu important, le client ne fera probablement pas défaut. On décide alors de remplacer par 1 million les valeurs au-dessus de ce seuil.


```{r, warning=FALSE}
as.data.frame(unique(Credit[Credit$Net_Annual_Income>=1000000, c("Y")]))
Credit$Net_Annual_Income[Credit$Net_Annual_Income>=1000000] = 1000000
  
```
On voit que la proportion de défaut baisse avec le revenu annuel net. Au-dessus de 60 000 euro net, la proportion de client faisant défaut est marginale.


```{r, echo=FALSE, warning=FALSE}
  ggplot(data = Credit[Credit$Net_Annual_Income<=100000,]) +
  geom_histogram(mapping = aes(x = Net_Annual_Income, fill = Y), alpha=0.5, bins=10)
  
```


# Analyse approfondie

On crée un nouveau jeu de données qui contient que les clients de niveau licence de catégorie NP et qui sont arrivés après 2010. Car ce sont eux qui ont le plus fait défaut. On va essayer d'identifier les variables qui expliquent la probabilité de défaut dans ce groupe.  
Maitenant on observe que les anciens clients de ce groupe font défaut à un rythme plus élevé que les nouveaux clients. 20% des anciens clients ont fait défaut contre 7% pour les nouveaux clients.

```{r}
Credit2 = Credit[Credit$Educational_Level=="University" & Credit$P_Client == "NP_Client" & Credit$CustomerOpenDateYear == ">2010",]
TableProp(Credit2, "Y", "Customer_Type")
  
```

Plus le client est jeune plus il est enclin à faire défaut.


```{r}

TableProp(Credit2, "Y", "AgeCat")
  
```
```{r}

TableProp(Credit2, "Y", "Marital_Status")
  
```

## Catégorie du prêt (Prod_Category, Prod_Sub_Category)

On voit que la catégorie de produit la plus populaire est B. Dans cette catégorie, le produit le plus demandé est de sous-catégorie C. Les clients avec un prêt de catégorie L et de sous-catégorie C sont ceux qui en proportion font le plus défaut. En résumé, la grande majorité des défauts concerne des client ayant souscrit un prêt de sous-catégorie C.

```{r, echo=FALSE}
ggplot(data = Credit2) +
geom_bar(mapping = aes(x = Prod_Sub_Category, fill = Y))+
facet_grid(~Prod_Category)
  
```


## Source du financement et type de résidence (Source, Type_Of_Residence)

Très peu de clients vivent dans le domicile parental. La grande majorité des défauts se font auprès des clients propriétaires. Ceci peut être expliqué par le fait que ces clients payent encore leur bien immobillier, ce qui diminue leur capacité de remboursement.


```{r, echo=FALSE}

ggplot(data = Credit2) +
geom_bar(mapping = aes(x = Source, fill = Y))+
facet_grid(~Type_Of_Residence)
  
```


## Durée du prêt (Credit_Duration)

On crèe de nouveau un jeu de donnée pour examiner l'effet de la durée de prêt. On prendra uniquement les clients propriétaires ayant souscrit un prêt de sous-catégorie C car ce sont eux qui font le plus défaut.

```{r}
Credit3 = Credit2[Credit2$Type_Of_Residence=="Owned" & Credit2$Prod_Sub_Category == "C",]
  
```

On remarque que les prêts de courte période sont ceux qui générent le plus de défaut chez les clients. Les prêts d'une durée supérieure à 16 mois sont à l'origine de très peu de défauts. Ce sont donc les crédits d'une durée inférieure à 1 an qui sont les plus à risque.

```{r, echo=FALSE, warning=FALSE}
  ggplot(data = Credit3) +
  geom_histogram(mapping = aes(x = Credit_Duration, fill = Y), alpha=0.5, bins=20)
  
```
  

## Nombre de produits (Nb_Of_Products)

La majorité des clients ne cumule qu'un seul prêt. Les clients ayant à leur charge le moins de personnes sont ceux qui ont tendance à cumuler le plus de prêts. En effet, comme leurs besoins sont plus importants, ils s'endettent plus.


```{r, echo=FALSE}

ggplot(data = Credit3) +
geom_bar(mapping = aes(x = Nb_Of_Products, fill = Y)) +
facet_grid(~Number_Of_DependantCat)
  
```

## Résumé

- La proportion de clients faisant défaut diminue avec l'âge. 
- La majorité des clients est arrivée après 2010, eux même faisant le plus de défaut.
- La majorité des défauts se produisent auprès de clients de type NP qui ont une licence et pas plus.
- Plus un client a un nombre important de personne à charge plus il est susceptible de faire défaut.
- Plus un individu vit depuis longtemps dans son logement actuel moins il est enclin à faire défaut.
- Au-dessus d'un certain seuil de salaire (600.000€), les clients ne font plus défaut.


# Classification supervisée

On se rappelle que le jeu de donnée est déséquilibré et ne pas prendre en compte ce fait pourrait endommager la qualité des classifieurs. Puisque le déséquilibre est très prononcé, on va utiliser le F1-Score comme critère pour selectionner le meilleur modèle lors de la validation croisée.
Le F1-Score est calculé à partir de la précision et du rappel (recall). Il s'agit enfait d'une moyenne harmonique de ces deux termes.

F1 = 2 * (PRE * REC) / (PRE + REC)

La précision est le nombre d'observations correctement identifié comme positif divisé par le nombre total de positifs prédits par le modèle. Autrement dit, dans notre cas, la précision mesure la proportion de clients correctement identifiée comme ayant fait défaut par le modèle sur le nombre total de clients prédits comme ayant fait défaut.

Le rappel nous donne la capacité du modèle à prédire correctement les clients faisant défaut. Il donne la proportion de clients prédit comme faisant défaut sur l'ensemble des clients qui ont vraiment fait défaut.

On se focalise sur le rappel car, si on se place du point de vue d'une banque, on veut que le taux de faux négatif soit le plus bas possible. En d'autres termes, on veut être capable d'identifier correctement le plus de clients susceptibles de faire défaut.

Les classifieurs devront avoir un taux de précision supérieur à 92.69%. Ce taux de précision correspond au classifieur qui prédit la classe majoritaire pour chaque observation.

On ne considére pas les modèles LDA et QDA puisque ces modèles reposent sur une hypothèse de normalité des variables explicatives.


```{r, echo=TRUE}
table(Credit$Y)/n
```

```{r, echo=TRUE, message=FALSE}
set.seed(2020)
Credit <- Credit %>% mutate_if(is.character,as.factor)
Credit$Y = factor(Credit$Y ,levels(Credit$Y)[c(2,1)])
trainIndex <- createDataPartition(Credit$Y, p = .8, list = FALSE, times = 1)
CreditTrain <- Credit[ trainIndex,]
CreditTest  <- Credit[-trainIndex,]

```

Le train set et le test set conservent bien les proportions initiales de la variable à expliquer.

```{r, echo=TRUE, message=FALSE}
table(CreditTrain$Y)/nrow(CreditTrain)
```

On réduit et centre les variables continues avant de les donner aux algorithmes de classification. Cela peut permettre à certains algorithmes de converger plus rapidement car ces variables auront le même ordre de grandeur.

```{r, echo=TRUE, message=FALSE}
pp_data <- preProcess(CreditTrain[,-1], method = c("center", "scale"))
pp_CreditTrain <- predict(pp_data, newdata = CreditTrain)
pp_CreditTest <- predict(pp_data, newdata = CreditTest)

```

On enlève les variables de type date car nous les avons transformés en des variables quantitatives.

```{r, echo=TRUE, message=FALSE}
formula = Y ~. -Customer_Open_Date -BirthDate -Prod_Decision_Date -Prod_Closed_Date -AgeCat -Number_Of_DependantCat -Years_At_ResidenceCat

```


## Régression logistique

La régression logistique est très utile car elle ne pose aucune hypothèse sur la loi des variables explicatives. Afin d'avoir des output Y compris entre 0 et 1, interprétable comme des probabilités, les predictions passent sous la fonction sigmoïde. Les paramètres théta assosiés aux variables explicatives sont obtenus en minimisant la fonction de coût de la régression logistique. On cherche donc les thétas tel que les prédictions soient les plus proches possible des valeurs actuelles de Y. Pour minimiser la fonction de coût on utilise l'algorithme de déscente de gradient.


```{r, echo=TRUE, message=FALSE, warning=FALSE}
LogRegClf <- glm(formula, data= pp_CreditTrain, family = binomial)
LogRegClf_pred <- predict(LogRegClf, pp_CreditTest, type="response")
LogRegClf_class  <- ifelse(LogRegClf_pred>=0.5, "DEFAULT", "NO_DEFAULT")

```

On observe un taux de succès de 100% sur le train set, c'est-à-dire que le modèle prédit parfaitement la classe de chaque observation. C'est un signe de sur-apprentissage, on voudrait plutôt savoir si le pouvoir explicatif du modèle reste aussi bon lorsqu'on a affaire à des observations non présentes dans le jeu de données. 
Sur le test set, on observe un taux de succès de 95.9%.


```{r, echo=FALSE, message=FALSE, warning=FALSE}
c("Accuracy score on train set" = sum(LogRegClf$y== as.numeric(pp_CreditTrain$Y=="DEFAULT"))/nrow(pp_CreditTrain),
  "Accuracy score on test set" = sum(LogRegClf_class == pp_CreditTest$Y)/nrow(pp_CreditTest))

```

On va stocker les coefficients dans un data frame pour les comparer aux coefficients pénalisés plus tard.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
CoeffDf = data.frame(LogReg= LogRegClf$coefficients)
```



## Régression logistique avec de la pénalisation (Lasso/Ridge/ElasticNet) 

La régréssion logistique est très sensible au sur-apprentissage car les thétas optimaux obtenus minimisent la fonction de coût du train set. Lorsque le modèle est victime de sur-apprentissage, les prédictions sur un autre jeu de données ne seront pas bonnes. La pénalisation ajoute un terme supplémentaire à la fonction de coût. Plus lambda est élevé plus la fonction de coût sera pénalisée et plus les coefficients seront contraints à diminuer vers 0. Ces méthodes permettent de réduire le sur-apprentissage et peuvent même aller jusqu'à effectuer une sélection de variable dans le cas de Lasso.

Pour chaque modèle, on va effectuer une validation croisée 5-fold. Et pour prendre en compte le déséquilibre entre les classes, à chaque itération on va tirer un échantillonnage stratifié pour conserver la même proportion que le jeu de donnée initial et pour éviter les tirages sans clients dans la catégorie défaut.

```{r, echo=TRUE, message=FALSE}
folds = 5
cvIndex <- createFolds(pp_CreditTrain$Y, folds, returnTrain = T)

fitControl <- trainControl(index = cvIndex, method = "cv", number = folds, classProbs = TRUE, summaryFunction = prSummary)

```

On crée une fonction pour afficher le taux de succès sur le test set et le train set. Le taux de succès étant la proportion de clients correctement classifiée par le modèle.

```{r, echo=TRUE, message=FALSE}
print_score <- function(model, trainData ,testData) {
testScore = sum(predict(model, newdata = testData)==testData$Y)/nrow(testData)
trainScore = sum(predict(RidgeClf, newdata = trainData)==trainData$Y)/nrow(trainData)
print(c("Accuracy score on train set:" = testScore, "Accuracy score on test set:" = trainScore))
}

```


### Lasso

La méthode Lasso peut ramener à zero les coefficients des variables explicatives non pertinentes. La pénalisation, de type l1, est présente dans la fonction de coût comme la somme de la valeur absolue des coefficients. Pour utiliser Lasso avec glmnet, on fixe alpha à 1. On va chercher dans une grille de valeurs le lambda optimal.

```{r, echo=TRUE, message=FALSE, warning = FALSE}
gridLasso = expand.grid(alpha=1, lambda=seq(0, 0.5, by = 0.01))

set.seed(2020)
LassoClf <- train(formula, data = pp_CreditTrain, method = "glmnet", 
                trControl = fitControl,
                 verbose = FALSE,
                 tuneGrid= gridLasso,
                metric = "F",
                family = "binomial",
                standardize = FALSE)

plot(LassoClf)  
```

Lorsque le paramètre lambda augmente, le F1-Score moyen, calculé par validation croisée, diminue. Le F1-Score est maximisé lorsque le lambda est égal à 0 et il est égal à 0.976.
Cependant, on est plus intéressé par la valeur du rappel. Donc on prendra le lambda égal à 0.05 car pour ce lambda le modèle est capable d'identifier parfaitement les clients faisant défaut tout en conservant la meilleure précision sous cette contrainte.

```{r}
head(LassoClf$results, 10)[,2:6]

```

```{r}
set.seed(2020)
LassoClfOpt <- train(formula, data = pp_CreditTrain, method = "glmnet", 
                trControl = fitControl,
                 verbose = FALSE,
                 tuneGrid= expand.grid(alpha=1, lambda=c(0.04, 0.05, 0.06)),
                metric = "F",
                family = "binomial",
                standardize=FALSE)

```



Le taux de succès sur le train set baisse par rapport au cas sans pénalisation, ce qui est naturel. Cependant les prédictions du modèle sur le test set sont moins bonnes. Le modèle classifie correctement 95% des observations sur le test set alors que la régréssion logistique à un taux de succès de 95.3%.


#print_score(LassoClfOpt, pp_CreditTrain, pp_CreditTest)



```{r}
CoeffDf["Lasso"] = as.data.frame(as.matrix(coef(LassoClfOpt$finalModel, LassoClfOpt$bestTune$lambda)))
```

### Ridge

Ridge est une autre méthode de contraction des coefficients, la pénalisation est de type l2.

```{r, echo=TRUE, message=FALSE, warning=FALSE}

gridRidge = expand.grid(alpha=0, lambda=seq(0, 0.05, by = 0.001))

set.seed(2020)
RidgeClf <- train(formula, data = pp_CreditTrain, method = "glmnet", 
                trControl = fitControl,
                 verbose = FALSE,
                 tuneGrid= gridRidge,
                metric = "F",
                family = "binomial",
                standardize=FALSE)

plot(RidgeClf) 

```

Le modèle Lasso est meilleur selon le critère du F1-Score. Comme pour le modèle Lasso, on choisira le lambda qui maximise le rappel sous la contrainte d'une precision la plus élevée possible. On trouve un lambda égal à 0.020. Sous ce lambda, la précision est de 94.79% et le rappel de 99%.


```{r}
RidgeClf$results[,2:6]

```


```{r}
set.seed(2020)
RidgeClfOpt <- train(formula, data = pp_CreditTrain, method = "glmnet", 
                trControl = fitControl,
                 verbose = FALSE,
                 tuneGrid= expand.grid(alpha=0, lambda=c(0.019, 0.020, 0.021)),
                metric = "F",
                family = "binomial",
                standardize=FALSE)

```


Le taux de succès sur le test set est le même que pour la méthode Lasso. Le taux de succès sur le train set est quand à lui plus élevé que celui de la méthode Lasso.
On préferera la méthode Lasso à la méthode Ridge, car Lasso atteint un même score sur le test set avec un nombre de variables explicatives inférieures. Le modèle Lasso est plus simple à priori.


```{r}
print_score(RidgeClfOpt, pp_CreditTrain, pp_CreditTest)
CoeffDf["Ridge"] = as.data.frame(as.matrix(coef(RidgeClfOpt$finalModel, RidgeClfOpt$bestTune$lambda)))
```

### Elastic Net

Elastic Net est une méthode de contraction de coefficients qui combine les pénalisations de Lasso et Ridge. On a un hyperparamètre supplémentaire à optimiser, il s'agit du paramètre alpha compris entre 0 et 1. Lorsque alpha est proche de 0, la pénalisation l2 (Ridge) est plus importante et lorsque alpha est proche de 1, la pénalisation l1 devient plus importante. On laisse la fonction glmnet et la fonction train de caret nous trouver les paramètres lambda et alpha optimaux.


```{r, echo=TRUE, message=FALSE, warning=FALSE}

set.seed(2020)
ENClf <- train(formula, data = pp_CreditTrain, method = "glmnet", 
                trControl = fitControl,
                 verbose = FALSE,
                metric = "F",
                family = "binomial",
               standardize=FALSE,
               tuneLength = 10)

```

Le choix des hyperparamétres lambda et alpha s'opère de la même manière que précédemment. On trouve un lambda égal à 0.05 et un alpha de 0.3.

```{r}

ENClf$results[,1:6][25:30,]


```


```{r}
set.seed(2020)
ENClfOpt <- train(formula, data = pp_CreditTrain, method = "glmnet", 
                trControl = fitControl,
                 verbose = FALSE,
                 tuneGrid= expand.grid(alpha=0.3, lambda=c(0.05, 0.051)),
                metric = "F",
                family = "binomial",
                standardize=FALSE)

```

On trouve un taux de succès sur le test set identique au taux de succès de Lasso et de Rdige.


```{r}
print_score(ENClfOpt, pp_CreditTrain, pp_CreditTest)
CoeffDf["ElasticNet"] = as.data.frame(as.matrix(coef(ENClf$finalModel, ENClf$bestTune$lambda)))

```

### Interprétation et sélection du meilleur modèle

Le nombre de variables explicatives est égal à 71.

```{r}
nrow(CoeffDf)

```

Les méthodes Lasso et Elastic Net peuvent faire de la sélection de variables en réduisant le coefficients à 0 de certaines variables. On observe que le modèle Lasso ne comporte qu'une seule variable explicative et il est capable de prédire aussi bien que les autres modèles la probabilité de faire défaut. Le modèle Elastic Net mets à 0 les coefficients de 19 variables explicatives.


```{r}
c(NbrElasicNet= sum(abs(CoeffDf$ElasticNet)>0), NbrLasso= sum(abs(CoeffDf$Lasso)>0)) -1


```


On montre pour l'instant uniquement les coefficients de la régression logistique supérieur à 10 en valeur absolue.
Le coefficient de la régression logistique le plus élevé en valeur absolue est le coefficient associé à la variable `Prod_Closed_DateYear2013`. Il est de signe négatif. Cela signifie qu'avoir une date de cloture fixée en 2013 réduit la probabilité de faire défaut. On voit que ce coefficient reste négatif quelque soit la pénalisation.

Les coefficients assossiés au dates de cloture en mois sont relativement élevés en valeur absolue, ce qui peut être un signe de sur-apprentissage. Leurs coefficients sont réduit lorsqu'on utilise la méthode Ridge et Elastic Net.
La méthode Lasso et Elastic Net fixe à 0 certains coefficients comme `Type_Of_ResidenceOwned`.

On remarque que les coefficients du modèle Ridge, Lasso et Elastic Net sont bien plus petits que les coefficients de la régréssion logistique, ce qui est l'effet de la pénalisation.

```{r}
CoeffDf[abs(CoeffDf)>10, ][-1,]

```

On observe que l'unique variable non égale à 0 dans le modèle Lasso est la durée du crédit. Plus la durée du crédit est longue moins le client sera enclin à faire défaut. 
Avec ce tableau, on voit bien que toutes les analyses dans la première partie sont vérifiées par le signe et la magnitude des coefficients.


```{r}
CoeffDf[abs(CoeffDf$ElasticNet)>0.15, ][-1,]

```

La méthode Lasso est capable de prédire la probabilité de défaut en utilisant que la durée de crédit, on ne prendra pas en compte ce modèle car il est jugé trop simpliste.

On pourrait considérer la méthode Elastic Net car même si la qualité de ses prédictions sur le test set est un peu plus bas que celle de la régréssion logistique, la méthode Elastic Net simplifie fortement le modèle car on passe de 71 variables à seulement à 52. Le taux de succès de cette méthode sur le test set est de 95%.

Cependant, on remarque que le modèle Ridge a un recall de 0.943%, ce qui est supérieur aux recall des autres modèles.
Etant donné son taux de succès de 95% et qu'il réduit certains coefficients vers 0, on le préferera aux autres modèles.

```{r}
recall(pp_CreditTest$Y, predict(ENClfOpt, newdata = pp_CreditTest)) 
recall(pp_CreditTest$Y, predict(RidgeClfOpt, newdata = pp_CreditTest)) 
recall(pp_CreditTest$Y, predict(LassoClfOpt, newdata = pp_CreditTest)) 

```

## KNN

La méthode des k plus proches voisins est un algorithme basé sur la distance entre les observations. Ainsi, dans le cas de la classification, pour chaque observation que l'on cherchera à prédire, l'algorithme déterminera tous les voisins qui sont assez proches, selon le critère de distance choisi et ensuite il prédira la classe majoritaire.

Il est également important de signaler que l’on devra choisir un K ni trop élevé ni trop faible car dans un cas on aura un mauvais classifieur puisqu' il regroupe des individus qui ne se ressemblent pas et dans un autre cas on aura un classifieur qui ne joue plus la fonction de classifieur vu qu'il ne regrouperait que peu d’individus. Le choix de K est donc primordial et se décide par validation croisée.

```{r, echo=TRUE, message=FALSE}

set.seed(2020)
KNNgrid = expand.grid(k = 1:50)
KNNClf <- train(formula, data = pp_CreditTrain, method = "knn", 
                trControl = fitControl,
                tuneGrid= KNNgrid,
                metric = "F")

plot(KNNClf)

```

On choisit k sous les mêmes conditions que précédemment. On trouve k = 50.

```{r}
KNNClf$results[,1:5]

```

```{r, echo=TRUE, message=FALSE}

set.seed(2020)
KNNgrid = expand.grid(k = 49:51)
KNNClfOpt <- train(formula, data = pp_CreditTrain, method = "knn", 
                trControl = fitControl,
                tuneGrid= KNNgrid,
                metric = "F")

```

On trouve un taux de succès de 95%.


```{r}
print_score(KNNClfOpt, pp_CreditTrain, pp_CreditTest)

```

Le recall est de 95.6%. Ce qui est supérieur aux modèles précédents. Ce modèle semble plus intéréssant.


```{r}
recall(pp_CreditTest$Y, predict(KNNClfOpt, newdata = pp_CreditTest)) 

```


## SVM

### SVM linéaire

Les SVM peuvent être utiles pour résoudre des problèmes de discriminations. Ils sont connus pour être très performants car ils peuvent être linéaires ou non-linéaires. L’idée des SVM est de trouver une surface de séparation afin de pouvoir classifier les observations.
Pour les classifications on peut séparer les deux classes par un hyperplan. Pour trouver la qualité de cet hyperplan on peut mesurer la distance entre les données d'apprentissage et l’hyperplan de séparation. Ainsi les SVM linéaires cherchent à maximiser la marge qui n’est autre que la distance entre le plus proche individus et l’hyperplan de séparation.  


```{r}
SVMLinearClf <- train(formula, data = pp_CreditTrain,
             method="svmLinear",trControl=fitControl,
             tuneGrid=data.frame(C=seq(1,10,1)),
             metric = "F")

plot(SVMLinearClf)

```

On choisit un C égal à 7.

```{r}
SVMLinearClf$results[,1:5]

```


```{r}
SVMLinearClfOpt <- train(formula, data = pp_CreditTrain,
             method="svmLinear",trControl=fitControl,
             tuneGrid=data.frame(C=c(6.9, 7.1)),
             metric = "F")


```


```{r}
print_score(SVMLinearClfOpt, pp_CreditTrain, pp_CreditTest)

```

Ayant un même taux de succès que les modèles précédents, on préferera pour l'instant ce modèle car il a le recall le plus élevé.

```{r}
recall(pp_CreditTest$Y, predict(SVMLinearClfOpt, newdata = pp_CreditTest)) 

```



## SVM non linéaire (gaussian)

```{r}
radialGrid = expand.grid(C = c(c(2,4,8,15)), sigma = c(0, 0.1, 0.5, 1, 5))

SVMradClf <- train(formula, data = pp_CreditTrain,
             method="svmRadial",trControl=fitControl,
             tuneGrid = radialGrid,
             metric = "F")

plot(SVMradClf)

```

On choisit comme hyperparamètre sigma égal à 0.1 et C égal à 2.

```{r}
SVMradClf$bestTune

```


```{r}
print_score(SVMradClf, pp_CreditTrain, pp_CreditTest)

```

Le recall est moins bon que celui du modèle SVM linéaire.

```{r}
recall(pp_CreditTest$Y, predict(SVMradClf, newdata = pp_CreditTest)) 

```

# Conclusion

Après une analyse graphique approfondie des données, nous avons essayé d'identifier les variables pouvant affecter la probabilité de défaut. 

Pour la sélection du modèle, nous nous basons sur le F1-Score et plus précisémment le rappel, qui doit être proche de 1, tout en ayant un taux de succès élevé.

Nous avons effectué de la validation croisée 5-fold, pour chaque modèle, afin de trouver les hyperparamètres qui maximisent le F1-Score sur le train set. Puis on a relevé la capacité de ces modèles à prédire des données non observées en examinant le taux de succès sur le test set.

Nous avons pu confirmer ensuite, la totalité des hypothèses émises de la partie analyse concernant le lien entre les variables explicatives et la probabilité de défaut. Nous avons vu que le modèle Lasso était capable d'expliquer correctement la probabilité de défaut avec uniquement une variable (durée du crédit). Ce modèle étant trop simpliste et éloigné de la réalité, nous l'avons rejeté.

Nous avons choisi le modèle SVM linéaire puisqu'il présente le plus haut rappel parmis tous les modèles étudiés, avec un taux de succès sur le test set identique aux autres.

Dans le contexte d'une banque, c'est le modèle SVM linéaire qui semble le plus efficace pour prédire la probabilité de défaut d'un client.

le Rappel du modèle SVM linéaire est égal à 0.963.

```{r}
recall(pp_CreditTest$Y, predict(SVMLinearClfOpt, newdata = pp_CreditTest)) 

```

```{r}
print_score(KNNClfOpt, pp_CreditTrain, pp_CreditTest)

```



